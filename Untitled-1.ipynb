{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data_146D7ADFDB (1).csv'\n",
    "data = pd.read_csv(filename)\n",
    "data\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick Inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NullRows = []\n",
    "for i in data.index:\n",
    "    if data.iloc[i].isnull().sum() > 100:\n",
    "        NullRows.append(i)\n",
    "\n",
    "NullRows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NullCols = pd.DataFrame({\"cols\":[],\n",
    "                         \"counts\":[]})\n",
    "\n",
    "for col in data.columns:\n",
    "    if data[col].isnull().sum() > 100:\n",
    "        df2 = pd.DataFrame({\"cols\":[col],\n",
    "        \"counts\":[[data[col].isnull().sum()]]})\n",
    "        NullCols = pd.concat([NullCols,df2])\n",
    "\n",
    "NullCols\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a \"key\" for identifying rows other than index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a key for the rows\n",
    "key = np.arange(1001,1410,1, dtype=int)\n",
    "key_ID = pd.DataFrame({\"key_ID\" : key})\n",
    "data2 = pd.concat([key_ID,data], axis = 1)\n",
    "data2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "separate benchmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "benches = data2[['key_ID','IWEIGHT','IWEIGHT_ENRL','ACTCOLL','STUEFF','ACCHALL','STUFAC','SUPPORT','ACTCOLL_STD','STUEFF_STD','ACCHALL_STD','STUFAC_STD','SUPPORT_STD']]\n",
    "metrics = data2.drop(columns=['IWEIGHT','IWEIGHT_ENRL','ACTCOLL','STUEFF','ACCHALL','STUFAC','SUPPORT','ACTCOLL_STD','STUEFF_STD','ACCHALL_STD','STUFAC_STD','SUPPORT_STD', 'CCSSE_ID','INSTITUTION']).fillna(99)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iffy = []\n",
    "for i in data.columns:\n",
    "    iffy.append(i)\n",
    "iffy\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick NA fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.fillna(99)\n",
    "data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation checks between benchmark scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(metrics['key_ID'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning to find the categories that predict the best"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for categories that predict each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics2 = metrics.drop(columns=['key_ID'])\n",
    "dfout = pd.DataFrame({\"col1\":[], \"col2\":[], \"R\":[], \"p\":[]}) \n",
    "dupes = []             \n",
    "for col in metrics2.columns:\n",
    "   array = np.asarray(metrics2[col])\n",
    "   for a in metrics2.columns:\n",
    "      dupel = f'{a} | {col}'\n",
    "      if a == col:\n",
    "         continue\n",
    "      elif dupel in dupes:\n",
    "         continue\n",
    "      else:\n",
    "         array2 = np.asarray(metrics2[a])\n",
    "         b = pearsonr(array, array2)\n",
    "         if b.pvalue < .01 and b.statistic > .95:\n",
    "            df2 = pd.DataFrame({\"col1\":[col], \"col2\":[a], \"R\":[b.statistic], \"p\":[b.pvalue]})\n",
    "            dfout = pd.concat([dfout, df2], ignore_index=True)\n",
    "            dupes.append(f'{col} | {a}')\n",
    "\n",
    "dfout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "outsy = dfout.sort_values(by=['R'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "outsy.to_csv('file_temp.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instructional cost study with brad\n",
    "that is a report that gets sent out every year to compare CIP codes between schools\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
